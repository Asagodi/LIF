{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asagodi/.local/lib/python2.7/site-packages/ipykernel_launcher.py:40: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/home/asagodi/.local/lib/python2.7/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(100, return_sequences=True, input_shape=(1, 784))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 1, 100)            88500     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 10)                1110      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trains a simple deep RNN on the MNIST dataset.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 1, 784)\n",
    "x_test = x_test.reshape(10000, 1, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train = y_train.reshape(60000,10)\n",
    "y_test = y_test.reshape(10000,10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.recurrent.SimpleRNN(100, input_dim=784, input_length=1, return_sequences=True))\n",
    "# model.add(keras.layers.recurrent.SimpleRNN(32, return_sequences=True))\n",
    "# model.add(keras.layers.recurrent.SimpleRNN(16, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform',\n",
    "#                                  recurrent_initializer='orthogonal', bias_initializer='zeros',\n",
    "#                                  kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None,\n",
    "#                                  activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None,\n",
    "#                                  bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=True))\n",
    "model.add(keras.layers.recurrent.SimpleRNN(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 10s - loss: 9.0730 - acc: 0.1857 - val_loss: 8.7882 - val_acc: 0.1403\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 9s - loss: 9.2809 - acc: 0.1604 - val_loss: 8.9952 - val_acc: 0.1944\n",
      "Test loss: 8.99519557343\n",
      "Test accuracy: 0.1944\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the recurrent weights like this is BS\n",
    "import tensorflow as tf\n",
    "x = model.weights[4]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "weight_mat = sess.run(x)    \n",
    "# print(v) # will show you your variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPcAAAD7CAYAAAC2TgIoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKeOWmjJuqan/BdcjDzQ7WzfTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbffc5e7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(weight_mat>0.2, interpolation='none', cmap=plt.cm.gray) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pattern_by_weight(neuron, weight_matrix, min_weight):\n",
    "    current_neuron = neuron\n",
    "    list_of_paths = [[neuron]] #paths are lists\n",
    "    while True:\n",
    "        for path in list_of_paths:\n",
    "            current_neuron = path[-1]\n",
    "            next_neurons = close_neighbours(current_neuron, weight_matrix, min_weight) #select close neighbours\n",
    "            #add next neuron in path\n",
    "            extended_paths = []\n",
    "            for nn in next_neurons:\n",
    "                if nn not in path:\n",
    "                    extended_paths.append(path + [nn])\n",
    "        print(extended_paths)\n",
    "        if extended_paths == []:\n",
    "            break\n",
    "        for ep in extended_paths:\n",
    "            if ep not in list_of_paths:\n",
    "                extended_paths.append(ep)\n",
    "        \n",
    "    return list_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def close_neighbours(neuron, weight_matrix, min_weight):\n",
    "    \"\"\"\n",
    "    Returns a list of neighbours that have a connection strength above min_weight.\n",
    "    \"\"\"\n",
    "    neighs = weight_matrix[neuron] #select connections to neighbours\n",
    "    cn = [abs(neighs) > min_weight] #select close neighbours\n",
    "    close_neuron_numbers = np.squeeze(np.arange(0, weight_matrix.shape[1]))[cn]\n",
    "    return close_neuron_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pattern_by_weight(neuron, weight_matrix, min_weight, max_length):\n",
    "    \"\"\"\n",
    "    Returns a list of all patterns that have a connection neurons with connection \n",
    "    strength above min_weight and are of maximal size max_length.\n",
    "    \"\"\"\n",
    "    current_neuron = neuron\n",
    "    list_of_paths = [[neuron]] #paths are lists\n",
    "    dict_of_paths = {}\n",
    "    i = 1\n",
    "    while i < max_length:\n",
    "        eep = []\n",
    "        for path in list_of_paths:\n",
    "#             print(\"Path\", path)\n",
    "            current_neuron = path[-1]\n",
    "#             print(\"Current\", current_neuron)\n",
    "            next_neurons = close_neighbours(current_neuron, weight_matrix, min_weight) #select close neighbours\n",
    "#             print(\"Next\", next_neurons)\n",
    "            #add next neuron in path\n",
    "            extended_paths = []\n",
    "            for nn in next_neurons:\n",
    "                if nn not in path:\n",
    "                    extended_paths.append(path + [nn])\n",
    "            eep.extend(extended_paths)\n",
    "#             print(\"EEP\", eep)\n",
    "        if eep == []:\n",
    "            break\n",
    "        list_of_paths = eep\n",
    "        i += 1\n",
    "        dict_of_paths[i] = eep\n",
    "    sorted_list_of_paths = [list(np.sort(p)) for p in list_of_paths]\n",
    "    sorted_list_of_paths.sort()\n",
    "    list_of_paths_nodups = list(sorted_list_of_paths for sorted_list_of_paths,\n",
    "                                        _ in itertools.groupby(sorted_list_of_paths))\n",
    "    return list_of_paths, list_of_paths_nodups, dict_of_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lp, lpnd, dp = find_pattern_by_weight(9, weight_mat, 0.42, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get weights from layer 1 to 2\n",
    "x = model.weights[3]\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "proj_weight_mat = sess.run(x)    \n",
    "\n",
    "#get weights in layer 1\n",
    "x = model.weights[1]\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "rec_weight_mat_1 = sess.run(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 11, 51, 41, 29, 23, 8, 57, 27]\n"
     ]
    }
   ],
   "source": [
    "patt_len = 10\n",
    "lp, lpnd, dp = find_pattern_by_weight(0, rec_weight_mat_1, 0.2142, patt_len)\n",
    "print(dp[patt_len][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colimit_of_pattern(pattern, weight_mat, input_strength = 1, activation = None):\n",
    "    inp = np.zeros(weight_mat.shape[0])\n",
    "    inp[pattern] = 1\n",
    "    if activation:\n",
    "        outp = inp.dot(weight_mat) > activation\n",
    "    else: outp = inp.dot(weight_mat)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAA/CAYAAAAFdbj4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbfb1a48310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outp = colimit_of_pattern(dp[patt_len][0], proj_weight_mat, activation=0.348)\n",
    "plt.imshow(outp.reshape(1,10), interpolation='none', cmap=plt.cm.gray) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check whether colimit is strongly connected\n",
    "#get weights in layer 1\n",
    "x = model.weights[4]\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "rec_weight_mat_2 = sess.run(x)    \n",
    "\n",
    "lp, lpnd, dp = find_pattern_by_weight(7, rec_weight_mat_2, 0.42, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: [[7, 2], [7, 4]], 3: [[7, 2, 5], [7, 4, 9]]}\n"
     ]
    }
   ],
   "source": [
    "print(dp)\n",
    "#there is at least one pattern that is like the colimit\n",
    "#but pattern for increased activation limit colimit is not in possible colimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
